match.map=list(M=list(nn="N", ll="L")),
#constants: fix an sd_v as a scaling parameter. fix variability in t0 at 0 (standard)
constants=c(sd_v.con.false=1, st0=0))
#p.vector will be used to specify prior means
#pick some numbers that seem somewhat sensible
p.vector <-   c(
t0.con  = 0.3  ,  t0.pm   = 0.3 ,
A = 0.5  ,
sd_v.con.true =1,  sd_v.pm.true =1,   sd_v.pm.false  =1,
B.con.N =1,         B.pm.N =1 ,
B.con.L =1  ,      B.pm.L  =1,
mean_v.nn.con.N =1, mean_v.ll.con.N =0,
mean_v.nn.pm.N =1, mean_v.ll.pm.N =0, mean_v.nn.con.L=0,
mean_v.ll.con.L =1, mean_v.nn.pm.L =0, mean_v.ll.pm.L =1)
#check.p.vector checks that the p.vector has all the parameters from the model
check.p.vector(p.vector, model)
#specify a prior with prior.p.dmc.
p.prior <-   prior.p.dmc(
#names and posterior means set by p1
p1=p.vector,
#truncated normals
dists=  rep("tnorm", length(p.vector)),
#standard deviations of prior
# param order :t0, A, sv, B, mv
p2= c(rep(1,2),1,rep(1,3),rep(1,4),rep(2,8)),
#lower bounds of prior. Same param order
#t0 0.1 to keep in plausible range
#starting point 0, sd_v 0, B (which is b-A) 0, rates no truncation
lower=c(rep(0.1,2),0,rep(0,3),rep(0,4), rep(NA, 8)),
#t0 upper bound 1s, the rest inf
upper=c(rep(1,2),rep(NA, length(p.vector)-2))
)
#binds the data and the model together into one object
dm <- data.model.dmc(dats,model)
#generates start points for the sampling process out of the prior.
top_samples <- h.samples.dmc(nmc = 180,p.prior,dm)
save(top_samples, file="top_samples.RData")
head(dats)
simulate.dmc(p.vector,model)
install.packages("rtdists")
your_directory<- "C:/Users/admin/Desktop/hunter_brewer"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("data/dats.RData")
###First I will specify a 'top' model that allows all
#major parameters to vary by PM:
#B, v, sv, t0
#This model.dmc function creates a big array that will assign parameters
# to the appropriate cell of the design
#check the array (parameters x design cell x accumulator) to check it worked
model <- model.dmc(
factors=list(S=c("nn", "ll"), cond= c("con", "pm")),
responses=c("N", "L"),
#Here is where we specify what can vary
p.map=list(A="1",B=c("cond", "R"),t0=c("cond"),mean_v=c("S", "cond", "R"),
sd_v=c("cond", "M"),st0="1"),
#match map scores true and false
match.map=list(M=list(nn="N", ll="L")),
#constants: fix an sd_v as a scaling parameter. fix variability in t0 at 0 (standard)
constants=c(sd_v.con.false=1, st0=0))
#p.vector will be used to specify prior means
#pick some numbers that seem somewhat sensible
p.vector <-   c(
t0.con  = 0.3  ,  t0.pm   = 0.3 ,
A = 0.5  ,
sd_v.con.true =1,  sd_v.pm.true =1,   sd_v.pm.false  =1,
B.con.N =1,         B.pm.N =1 ,
B.con.L =1  ,      B.pm.L  =1,
mean_v.nn.con.N =1, mean_v.ll.con.N =0,
mean_v.nn.pm.N =1, mean_v.ll.pm.N =0, mean_v.nn.con.L=0,
mean_v.ll.con.L =1, mean_v.nn.pm.L =0, mean_v.ll.pm.L =1)
#check.p.vector checks that the p.vector has all the parameters from the model
check.p.vector(p.vector, model)
#specify a prior with prior.p.dmc.
p.prior <-   prior.p.dmc(
#names and posterior means set by p1
p1=p.vector,
#truncated normals
dists=  rep("tnorm", length(p.vector)),
#standard deviations of prior
# param order :t0, A, sv, B, mv
p2= c(rep(1,2),1,rep(1,3),rep(1,4),rep(2,8)),
#lower bounds of prior. Same param order
#t0 0.1 to keep in plausible range
#starting point 0, sd_v 0, B (which is b-A) 0, rates no truncation
lower=c(rep(0.1,2),0,rep(0,3),rep(0,4), rep(NA, 8)),
#t0 upper bound 1s, the rest inf
upper=c(rep(1,2),rep(NA, length(p.vector)-2))
)
#binds the data and the model together into one object
dm <- data.model.dmc(dats,model)
#generates start points for the sampling process out of the prior.
top_samples <- h.samples.dmc(nmc = 180,p.prior,dm)
save(top_samples, file="top_samples.RData")
#
str(dats)
dats
# Initial coding:
# accuracy: 0 = incorrect, 1 = correct (which you can delete)
# RT (in seconds)
# block: 0 = control block, 1 = PM block
# stim type (correct response): 0 = nonliving, 1 = living
# response (actual response): 0 = nonliving, 1 = living
your_directory<- "C:/Users/admin/Desktop/hunter_brewer"
setwd(your_directory)
dats <- read.csv("data/data.csv")
#Easier levels
dats$stimtype <- factor(dats$stimtype, labels= c("nn", "ll"),
levels= c(0, 1))
dats$RESPONSE <- factor(dats$RESPONSE, labels= c("N", "L"),
levels= c(0, 1))
dats$Block <- factor(dats$Block, labels= c("con", "pm"),
levels= c(0, 1))
#drop acc column
dats <- dats[-2]
#column order expected by dmc (R/RT last two columns, s first)
dats <- dats[,c(1,3,4,5,2)]
#easier colnames/colnames expected by dmc (s,..other factors..,S,R,RT)
names(dats) <- c("s", "cond", "S", "R", "RT")
dats$s <- factor(dats$s)
save(dats, file="data/dats.RData")
your_directory<- "C:/Users/admin/Desktop/hunter_brewer"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("data/dats.RData")
###First I will specify a 'top' model that allows all
#major parameters to vary by PM:
#B, v, sv, t0
#This model.dmc function creates a big array that will assign parameters
# to the appropriate cell of the design
#check the array (parameters x design cell x accumulator) to check it worked
model <- model.dmc(
factors=list(S=c("nn", "ll"), cond= c("con", "pm")),
responses=c("N", "L"),
#Here is where we specify what can vary
p.map=list(A="1",B=c("cond", "R"),t0=c("cond"),mean_v=c("S", "cond", "R"),
sd_v=c("cond", "M"),st0="1"),
#match map scores true and false
match.map=list(M=list(nn="N", ll="L")),
#constants: fix an sd_v as a scaling parameter. fix variability in t0 at 0 (standard)
constants=c(sd_v.con.false=1, st0=0))
#p.vector will be used to specify prior means
#pick some numbers that seem somewhat sensible
p.vector <-   c(
t0.con  = 0.3  ,  t0.pm   = 0.3 ,
A = 0.5  ,
sd_v.con.true =1,  sd_v.pm.true =1,   sd_v.pm.false  =1,
B.con.N =1,         B.pm.N =1 ,
B.con.L =1  ,      B.pm.L  =1,
mean_v.nn.con.N =1, mean_v.ll.con.N =0,
mean_v.nn.pm.N =1, mean_v.ll.pm.N =0, mean_v.nn.con.L=0,
mean_v.ll.con.L =1, mean_v.nn.pm.L =0, mean_v.ll.pm.L =1)
#check.p.vector checks that the p.vector has all the parameters from the model
check.p.vector(p.vector, model)
#specify a prior with prior.p.dmc.
p.prior <-   prior.p.dmc(
#names and posterior means set by p1
p1=p.vector,
#truncated normals
dists=  rep("tnorm", length(p.vector)),
#standard deviations of prior
# param order :t0, A, sv, B, mv
p2= c(rep(1,2),1,rep(1,3),rep(1,4),rep(2,8)),
#lower bounds of prior. Same param order
#t0 0.1 to keep in plausible range
#starting point 0, sd_v 0, B (which is b-A) 0, rates no truncation
lower=c(rep(0.1,2),0,rep(0,3),rep(0,4), rep(NA, 8)),
#t0 upper bound 1s, the rest inf
upper=c(rep(1,2),rep(NA, length(p.vector)-2))
)
#binds the data and the model together into one object
dm <- data.model.dmc(dats,model)
#generates start points for the sampling process out of the prior.
top_samples <- h.samples.dmc(nmc = 180,p.prior,dm)
save(top_samples, file="top_samples.RData")
#
your_directory<- "D:code/proactive_ids"
setwd(your_directory)
setwd("D:/code/proactive_ids")
your_directory<- "D:/code/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("top_samples_LBA.RData")
gelman.diag.dmc(top_samples)
plot.dmc(top_samples_LBA)
plot.dmc(top_samples)
plot.dmc(top_samples[[50]])
plot.dmc
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc <- function(samples,hyper=FALSE,location=FALSE,scale=FALSE,
start=1,end=NA,thin=1,save.ll=FALSE,
main.pll=NULL,pll.chain=FALSE,pll.together=TRUE,pll.barplot=FALSE,
only.prior=FALSE,only.like=FALSE,subject=1,collapse.subjects=FALSE,
layout=NA,smooth=FALSE,density=FALSE,p.prior=NULL,
prior.col = "red", post.col = "black",
prior.lwd = 1, post.lwd = 1,
prior.lty = 1, post.lty = 1,
...)
{
my.chain.plot <- function(chain.pll,thin=1,main.pll=NULL) {
x <- 1:dim(chain.pll)[1]
x <- x[x %% thin == 0]
ylim <- c(min(chain.pll),max(chain.pll))
plot(x,chain.pll[x,1],xlab="Iterations",ylab="",ylim=ylim,type="l",main=main.pll)
for (i in 2:dim(chain.pll)[2]) lines(x,chain.pll[x,i],col=i,lty=i)
}
auto.layout <- any(is.na(layout))
if ( location | scale ) {
if (location & scale)
stop("You must choose only one of location and scale.")
hyper <- attr(samples,"hyper")
if (is.null(hyper))
stop("There are no hyper-parameters to plot.")
if (location) {
samples <- list(theta=hyper$phi[[1]],nmc=hyper$nmc)
if (exists("p.prior")) p.prior <- p.prior[[1]]
} else {
samples <- list(theta=hyper$phi[[2]],nmc=hyper$nmc)
if (exists("p.prior")) p.prior <- p.prior[[2]]
}
pll.chain <- FALSE
pll.barplot <- FALSE
hyper <- FALSE
}
if ( hyper ) {
hyper <- attr(samples,"hyper")
if (is.null(hyper))
stop("There are no hyper-parameters to plot.")
if ( is.na(end) ) end <- hyper$nmc
if ( end <= start )
stop("End must be greater than start")
if ( pll.chain | pll.barplot ) {
chain.pll <- hyper$h_summed_log_prior[start:end,] +
hyper$h_log_likelihoods[start:end,]
colnames(chain.pll) <- 1:dim(chain.pll)[2]
if (pll.barplot) {
mean.ll <- apply(chain.pll,2,mean)
names(mean.ll) <- 1:length(mean.ll)
barplot(mean.ll,ylab="Mean Post Like",main=main.pll)
if (save.ll) mean.ll
} else {
if (!auto.layout) par(mfrow=layout)
if (!pll.together)
plot(mcmc(chain.pll,thin=thin),auto.layout=auto.layout,
density=density,smooth=smooth,...) else
plot(mcmc.list(lapply(data.frame(chain.pll),function(x){
mcmc(x,thin=thin)})),auto.layout=auto.layout,
density=density,smooth=smooth,
p.prior=p.prior, prior.col = prior.col,
prior.lwd = prior.lwd,
prior.lty = prior.lty,...)
}
} else {
if (!auto.layout) par(mfrow=layout)
plot(window(phi.as.mcmc.list(hyper,start=start,end=end,thin=1)),
auto.layout=auto.layout,density=density,smooth=smooth,
p.prior=p.prior,
prior.col = prior.col, post.col = post.col,
prior.lwd = prior.lwd, post.lwd = post.lwd,
prior.lty = prior.lty, post.lty = post.lty,...)
}
} else {
if ( is.null(samples$theta) ) {
if ( collapse.subjects ) samples <- collapse.subjects(samples) else
samples <- samples[[subject]]
}
if ( is.na(end) ) end <- samples$nmc
if ( end <= start ) stop("End must be greater than start")
if ( pll.chain | pll.barplot ) {
if ( only.prior ) chain.pll <- samples$summed_log_prior[start:end,] else
if ( only.like ) chain.pll <- samples$log_likelihoods[start:end,] else
chain.pll <- samples$summed_log_prior[start:end,] +
samples$log_likelihoods[start:end,]
colnames(chain.pll) <- 1:dim(chain.pll)[2]
if ( pll.barplot ) {
mean.ll <- apply(chain.pll,2,mean)
names(mean.ll) <- 1:length(mean.ll)
barplot(mean.ll,ylab="Mean Post Like",main=main.pll)
if (save.ll) mean.ll
} else {
if ( !auto.layout ) par(mfrow=layout)
if ( !pll.together )
plot(mcmc(chain.pll,thin=thin),auto.layout=auto.layout,
density=density,smooth=smooth,main.pll=main.pll) else {
if (!density & !smooth) my.chain.plot(chain.pll,thin=thin,main.pll=main.pll,...) else
plot(mcmc.list(lapply(data.frame(chain.pll),function(x){
mcmc(x)})),auto.layout=auto.layout,
density=density,smooth=smooth, ...)
}
}
} else {
if (!auto.layout) par(mfrow=layout)
plot(window(theta.as.mcmc.list(samples,thin=thin),start=start,end=end),
auto.layout=auto.layout,density=density,smooth=smooth,
p.prior=p.prior,
prior.col = prior.col, post.col = post.col,
prior.lwd = prior.lwd, post.lwd = post.lwd,
prior.lty = prior.lty, post.lty = post.lty,...)
}
}
}
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior, density=TRUE)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
install.packages("C:/Users/ljgs/Downloads/DMC-171128/DMC-171128/packages/coda_0.19-2.tar.gz", repos = NULL, type = "source")
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
your_directory<- "D:/code/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("top_samples_LBA.RData")
plot.dmc(top_samples[[2]], p.prior=top_samples[[2]]$p.prior)
your_directory<- "D:/code/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("top_samples_LBA.RData")
load("top_lba_PP.RData")
GET.fitgglist.dmc <- function (
PP, factors=NA, noR = FALSE,
quantiles.to.get = c(0.1, 0.5, 0.9), CI= c(0.025, 0.975),
acc.fun=function(x){as.numeric(x$S)==as.numeric(x$R)},
correct.only=FALSE,error.only=FALSE
) {
sim <- do.call(rbind, PP)
# Do the same for the data
data <- lapply(PP, function(x) attr(x, "data"))
data <- do.call(rbind, data)
get.fitgglist.dmc (sim,data, factors=factors, noR=noR, quantiles.to.get=quantiles.to.get,
CI=CI, acc.fun=acc.fun, correct.only=correct.only, error.only=
error.only)
}
fit <- GET.fitgglist.dmc(PP, noR=T)
fit[[1]]
accs <- fit[[1]][fit[[1]]$R=="TRUE",]
accs
accs <- accs[,-accs$R]
accs <- accs[,-("R")]
accs <- accs[,-3]
accs
ggplot.RP.dmc(accs, xaxis="cond")
summary <- summary.dmc(top_samples)
save(summary, file="summary.RData")
summary$statistics
str(summary)
summary.dmc
h.run.converge.dmc
#Plan is for this file to have all the specification of the LBA models of the data
# - i.e., the 'top' model and then the reduced models with parameters fixed
your_directory<- "~/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("data/dats.RData")
h.run.converge.dmc
load("D:/code/proactive_ids/top_samples_LBA.RData")
##Hierarchical priors
p1 <- get.p.vector(top_samples[[1]])[names(p.prior)]
s.prior <- prior.p.dmc(p1=p1,p2=p1,
dists=rep("gamma",length(p1)))
oad fixed-effects fitting
load("top_samples_LBA.RData")
##Hierarchical priors
p1 <- get.p.vector(top_samples[[1]])[names(p.prior)]
#Plan is for this file to have all the specification of the LBA models of the data
# - i.e., the 'top' model and then the reduced models with parameters fixed
your_directory<- "~/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("data/dats.RData")
###First I will specify a 'top' model that allows all
#major parameters to vary by PM:
#B, v, sv, t0
#This model.dmc function creates a big array that will assign parameters
# to the appropriate cell of the design
#check the array (parameters x design cell x accumulator) to check it worked
model <- model.dmc(
factors=list(S=c("nn", "ll"), cond= c("con", "pm")),
responses=c("N", "L"),
#Here is where we specify what can vary
p.map=list(A="1",B=c("cond", "R"),t0=c("cond"),mean_v=c("S", "cond", "R"),
sd_v=c("cond", "M"),st0="1"),
#match map scores true and false
match.map=list(M=list(nn="N", ll="L")),
#constants: fix an sd_v as a scaling parameter. fix variability in t0 at 0 (standard)
constants=c(sd_v.con.false=1, st0=0))
#p.vector will be used to specify prior means
#pick some numbers that seem somewhat sensible
p.vector <-   c(
t0.con  = 0.3  ,  t0.pm   = 0.3 ,
A = 0.5  ,
sd_v.con.true =1,  sd_v.pm.true =1,   sd_v.pm.false  =1,
B.con.N =1,         B.pm.N =1 ,
B.con.L =1  ,      B.pm.L  =1,
mean_v.nn.con.N =1, mean_v.ll.con.N =0,
mean_v.nn.pm.N =1, mean_v.ll.pm.N =0, mean_v.nn.con.L=0,
mean_v.ll.con.L =1, mean_v.nn.pm.L =0, mean_v.ll.pm.L =1)
#check.p.vector checks that the p.vector has all the parameters from the model
check.p.vector(p.vector, model)
#specify a prior with prior.p.dmc.
p.prior <-   prior.p.dmc(
#names and posterior means set by p1
p1=p.vector,
#truncated normals
dists=  rep("tnorm", length(p.vector)),
#standard deviations of prior
# param order :t0, A, sv, B, mv
p2= c(rep(1,2),1,rep(1,3),rep(1,4),rep(2,8)),
#lower bounds of prior. Same param order
#t0 lower bound 0.1 seconds
#starting point 0, sd_v 0, B (which is b-A) 0, rates no truncation
lower=c(rep(0.1,2),0,rep(0,3),rep(0,4), rep(NA, 8)),
#t0 upper bound 1s, the rest inf
upper=c(rep(1,2),rep(NA, length(p.vector)-2))
)
#binds the data and the model together into one object
dm <- data.model.dmc(dats,model)
#generates start points for the sampling process out of the prior.
#We will save off samples here, then deploy them on the newcastle supercomputing
#grid (using grid_dispatch.R)
# top_samples <- h.samples.dmc(nmc = 180,p.prior,dm)
#load fixed-effects fitting
load("top_samples_LBA.RData")
##Hierarchical priors
p1 <- get.p.vector(top_samples[[1]])[names(p.prior)]
p1
s.prior <- prior.p.dmc(p1=p1,p2=p1,
dists=rep("gamma",length(p1)))
s.prior
#Plan is for this file to have all the specification of the LBA models of the data
# - i.e., the 'top' model and then the reduced models with parameters fixed
your_directory<- "~/proactive_ids"
setwd(your_directory)
source("dmc/dmc.R")
load_model("LBA", "lba_B.R")
load("data/dats.RData")
###First I will specify a 'top' model that allows all
#major parameters to vary by PM:
#B, v, sv, t0
#This model.dmc function creates a big array that will assign parameters
# to the appropriate cell of the design
#check the array (parameters x design cell x accumulator) to check it worked
model <- model.dmc(
factors=list(S=c("nn", "ll"), cond= c("con", "pm")),
responses=c("N", "L"),
#Here is where we specify what can vary
p.map=list(A="1",B=c("cond", "R"),t0=c("cond"),mean_v=c("S", "cond", "R"),
sd_v=c("cond", "M"),st0="1"),
#match map scores true and false
match.map=list(M=list(nn="N", ll="L")),
#constants: fix an sd_v as a scaling parameter. fix variability in t0 at 0 (standard)
constants=c(sd_v.con.false=1, st0=0))
#p.vector will be used to specify prior means
#pick some numbers that seem somewhat sensible
p.vector <-   c(
t0.con  = 0.3  ,  t0.pm   = 0.3 ,
A = 0.5  ,
sd_v.con.true =1,  sd_v.pm.true =1,   sd_v.pm.false  =1,
B.con.N =1,         B.pm.N =1 ,
B.con.L =1  ,      B.pm.L  =1,
mean_v.nn.con.N =1, mean_v.ll.con.N =0,
mean_v.nn.pm.N =1, mean_v.ll.pm.N =0, mean_v.nn.con.L=0,
mean_v.ll.con.L =1, mean_v.nn.pm.L =0, mean_v.ll.pm.L =1)
#check.p.vector checks that the p.vector has all the parameters from the model
check.p.vector(p.vector, model)
#specify a prior with prior.p.dmc.
p.prior <-   prior.p.dmc(
#names and posterior means set by p1
p1=p.vector,
#truncated normals
dists=  rep("tnorm", length(p.vector)),
#standard deviations of prior
# param order :t0, A, sv, B, mv
p2= c(rep(1,2),1,rep(1,3),rep(1,4),rep(2,8)),
#lower bounds of prior. Same param order
#t0 lower bound 0.1 seconds
#starting point 0, sd_v 0, B (which is b-A) 0, rates no truncation
lower=c(rep(0.1,2),0,rep(0,3),rep(0,4), rep(NA, 8)),
#t0 upper bound 1s, the rest inf
upper=c(rep(1,2),rep(NA, length(p.vector)-2))
)
#binds the data and the model together into one object
dm <- data.model.dmc(dats,model)
#generates start points for the sampling process out of the prior.
#We will save off samples here, then deploy them on the newcastle supercomputing
#grid (using grid_dispatch.R)
# top_samples <- h.samples.dmc(nmc = 180,p.prior,dm)
#load fixed-effects fitting
load("top_samples_LBA.RData")
##Hierarchical priors
# use same priors for hierarchical means as the individual subject priors
# use gamma distributions for hierarchical sd priors
p1 <- get.p.vector(top_samples[[1]])[names(p.prior)]
s.prior <- prior.p.dmc(p1=p1,p2=p1,
dists=rep("gamma",length(p1)))
pp.prior=list(p.prior,s.prior)
hstart <- make.hstart(top_samples)
theta1 <- make.theta1(top_samples)
h_top_samples <- h.samples.dmc(nmc=180,p.prior,dm,pp.prior,
hstart.prior=hstart,theta1=theta1,thin=1)
##Request all the cores available on cl2
cores=64
